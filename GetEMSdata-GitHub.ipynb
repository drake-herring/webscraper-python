{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook was written to scrape a publically listed emergency call log for the Eugene OR area. It may be useful as a guide for projects that need to scrape data from a webpage with dynamically generated content from a javascript interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver #selenium is used to interact with the webpage, so the program can 'click' buttons.\n",
    "import pandas as pd #the data will be saved locally as a csv file. Pandas is a nice way to write/read/work with those files.\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary #This will let the program open the webpage on a new Firefox window.\n",
    "from bs4 import BeautifulSoup #BeautifulSoup is used to parse the HTML of the downloaded website to find the particular information desired.\n",
    "import time #I will need to delay the program to give the webpage time to open. time will be used for that.\n",
    "import sys #This is only used to assign a location to my path. The location where I have a needed file for selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next section adds my current directory to my path. The main reason for this is selenium. Selenium uses geckodriver to talk with Firefox. That application is something you have to download special. Ideally, I would have geckodriver in a folder in python's path already. Instead, I just have it saved into the same folder I'm collecting all my data from the EMS call log. Not great, I know, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path\n",
    "sys.path.append('/path/to/the/example_file.py')\n",
    "sys.path.append('C:\\\\Users\\\\Kyle\\\\Documents\\\\Blog Posts\\\\EugeneEMSCalls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call log website gives the date with the month abbreviation. This dictionary lets me easily convert that into a 2 number string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Months={'Jan':'01','Feb':'02','Mar':'03','Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#url of the website with the call log data\n",
    "url='http://coeapps.eugene-or.gov/ruralfirecad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section opens a new window of Firefox browser. This is the tab where the url will be loaded and where the code will 'click' javascript buttons and download the HTML of the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binary = FirefoxBinary('C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe')\n",
    "driver = webdriver.Firefox(firefox_binary=binary)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Calls on Jan 9, 2017: 107\n"
     ]
    }
   ],
   "source": [
    "#quick check to see if selenium correctly got to the page. \n",
    "#this searches the HTML of the page for the HTML element id'd as 'callSummary',\n",
    "#and prints the text.\n",
    "summary=driver.find_element_by_id('callSummary').text\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping code. The way this deals with time is a bit wonky. Initially, it will step through every day of the current month from first day to last day. Those days that are still in the future won't have any calls and will not be saved into csv files. Then, the program steps back one month and repeats; again, going from the first to the last day. Eventually, the program reaches the set end date, where it breaks out of the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endIt=0;\n",
    "while endIt==0:\n",
    "    calendarOptions=driver.find_element_by_id('calendar').text.split()\n",
    "    monthsDays=[];\n",
    "    for elm in calendarOptions:\n",
    "        try:\n",
    "            potlDay=int(elm)\n",
    "            if potlDay<=31:\n",
    "                monthsDays.append(elm)\n",
    "        except:\n",
    "            pass\n",
    "    for day in monthsDays:\n",
    "        driver.find_element_by_link_text(day).click()\n",
    "        time.sleep(1) #giving firefox time to open.\n",
    "        summary=driver.find_element_by_id('callSummary').text;\n",
    "        dateData=summary[summary.index('on')+3:summary.index(':')].replace(',','').split(' ');\n",
    "        if len(dateData[1])==1:\n",
    "            dateData[1]='0'+dateData[1]\n",
    "        date=int(dateData[2]+str(Months[dateData[0]])+dateData[1]);\n",
    "        if int(date)==20161201: #End date is located here.\n",
    "            endIt=1;\n",
    "            break\n",
    "        html = driver.page_source;\n",
    "        soup = BeautifulSoup(html,'lxml'); #using BeautifulSoup to find the call logs.\n",
    "        EMSdata=soup.find('table', class_='tablesorter');\n",
    "        colNames1=EMSdata.thead.findAll('th') #recording the column names.\n",
    "        colNames2=[];\n",
    "        data1=[]\n",
    "        for x in range(0,len(colNames1)):\n",
    "            colNames2.append(colNames1[x].string.strip()) #saving each column value.\n",
    "            data1.append([])\n",
    "        for row in EMSdata.findAll(\"tr\"): #saving the individual call log data.\n",
    "            cells = row.findAll('td')\n",
    "            if len(cells)==len(colNames1):\n",
    "                for y in range(0,len(cells)):\n",
    "                    data1[y].append(cells[y].string.strip())\n",
    "        EMSdata1=pd.DataFrame(); #initializing a data frame to save 1 days worth of calls.\n",
    "        for x in range(0,len(colNames2)):\n",
    "            EMSdata1[colNames2[x]]=data1[x]\n",
    "        EMSdata1['Date']=date;\n",
    "        try:\n",
    "            EMSdata1.to_csv('%s.csv'%(EMSdata1.loc[0,'Date']),index=False) #saving csv file of daily call logs.\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(1) #giving time to save csv before moving on.\n",
    "    if endIt==0:\n",
    "        driver.find_element_by_link_text('Prev').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
